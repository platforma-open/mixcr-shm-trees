self := import("@platforma-sdk/workflow-tengo:tpl")

llPFrames := import("@platforma-sdk/workflow-tengo:pframes.ll")
ll := import("@platforma-sdk/workflow-tengo:ll")
maps := import("@platforma-sdk/workflow-tengo:maps")
assets := import("@platforma-sdk/workflow-tengo:assets")
render := import("@platforma-sdk/workflow-tengo:render")
xsv := import("@platforma-sdk/workflow-tengo:pframes.xsv")
text := import("text")
exportSettings := import(":export-settings")
prepareDonorColumn := import(":prepare-donor-column")
pframes := import("@platforma-sdk/workflow-tengo:pframes")

reconstructShmTreesTpl := assets.importTemplate(":reconstruct-shm-trees")

// this templete should run only after resolving of all inputs
// we don't need to wait for file content, just refs
self.awaitState("datasets", { wildcard: "*" }, "data", "InputsLocked")
// but we need spec already
self.awaitState("datasets", { wildcard: "*" }, "spec", "ResourceReady")
self.awaitState("donorColumn", "ResourceReady")
self.awaitState("params", "ResourceReady")

soiTpl := assets.importTemplate(":soi")

self.body(func(inputs) {
	// overall description of data that we have.
    dataDescription := {
		hasUmiTags: false,
		hasCellTags: false,
		// will be filled
		coveredFeatures: [],
		cellsAssembled: false
	}

	// clonotypingBlockId -> "bulk" | "sc"
	datasetTypes := {}

	assemblingFeature := ""
	for clonotypingBlockId, dataset in inputs.datasets {
		presetAnnotations := dataset.get("spec").getDataAsJson()["annotations"]

		datasetTypes[clonotypingBlockId] = "bulk"

		if presetAnnotations["mixcr.com/cellTags"] != "" {
			dataDescription.hasCellTags = true
		}
		if presetAnnotations["mixcr.com/umiTags"] != "" {
			dataDescription.hasUmiTags = true
		}
		if presetAnnotations["mixcr.com/cellsAssembled"] == "true" {
			dataDescription.cellsAssembled = true
			datasetTypes[clonotypingBlockId] = "sc"
		}
		dataDescription.coveredFeatures = text.re_split(',', presetAnnotations["mixcr.com/coveredFeaturesOnExport"])
		// check that assemblingFeature feature is the same. If so, coveredFeatures will be the same too
		if (assemblingFeature == "") {
			assemblingFeature = presetAnnotations["mixcr.com/assemblingFeature"]
		} else if (assemblingFeature != presetAnnotations["mixcr.com/assemblingFeature"]) {
			ll.panic("Assmble features should be the same to process tress. Got " + assemblingFeature + " and " + presetAnnotations["mixcr.com/assemblingFeature"])
		}
	}

	// adding assembling feature to the list of covered features
	dataDescription.coveredFeatures = append(dataDescription.coveredFeatures, assemblingFeature)

	// there should be call join on pfFrames, but it's not implements, so we will do it by hand
	dataGroupedByDonorId := prepareDonorColumn.groupDataByDonorId(inputs.donorColumn, inputs.datasets)

	// collect params for running export commands and to parse result tsv files into pColumns
	shmTreeTableOptions := exportSettings.shmTreeTableOptions(dataDescription)
	shmTreeNodesTableOptions := exportSettings.shmTreeNodesTableOptions(dataDescription)
	shmTreeNodesWithClonesTableOptions := exportSettings.shmTreeNodesWithClonesTableOptions(dataDescription, inputs.donorColumn)

	// TODO that call is too low level. Should be replaced with something that works with pColumns, not data only
	mixcrResults := llPFrames.aggregate(
		// files to iterate through
		dataGroupedByDonorId.data,
		// columns not to combine - sampleId and mixcrBlockId
		[1, 2],
		reconstructShmTreesTpl,
		// all the outputs that should be gethered
		[
			{
				"name": "trees",
				"type": "Resource"
			}, {
				"name": "treeNodes",
				"type": "Resource"
			}, {
				"name": "treeNodesWithClones",
				"type": "Resource"
			}, {
				"name": "tsvs",
				"type": "Resource"
			}, {
				"name": "allelesLog",
				"type": "Resource"
			}, {
				"name": "treesLog",
				"type": "Resource"
			}, {
				"name": "allelesReport",
				"type": "Resource"
			}, {
				"name": "treesReport",
				"type": "Resource"
			}, {
				"name": "allelesReportJson",
				"type": "Resource"
			}, {
				"name": "treesReportJson",
				"type": "Resource"
			}
		],
		false,
		// inputs
		{
			"shmTreeTableOptions": shmTreeTableOptions["cmdArgs"],
			"shmTreeNodesTableOptions": shmTreeNodesTableOptions["cmdArgs"],
			"shmTreeNodesWithClonesTableOptions": shmTreeNodesWithClonesTableOptions["cmdArgs"],
			"globalParams": maps.merge(
				inputs.params,
				{ datasetTypes: datasetTypes }
			)
		}
	)

	// donorId axis is inherited from dataGroupedByDonorId and we should specify it explicitly (other axes will be supplied by pfconvParams)
	additionalArgsForImportTsv := {
		additionalAxesSpec: dataGroupedByDonorId["spec"]["axesSpec"][:1]
	}

	trees := xsv.importFileMap(
        mixcrResults.output("trees"),
        "tsv",
        shmTreeTableOptions["pfconvParams"],
        additionalArgsForImportTsv
    )

	treeNodes := xsv.importFileMap(
        mixcrResults.output("treeNodes"),
        "tsv",
        shmTreeNodesTableOptions["pfconvParams"],
        additionalArgsForImportTsv
    )

	treeNodesWithClones := xsv.importFileMap(
        mixcrResults.output("treeNodesWithClones"),
        "tsv",
        shmTreeNodesWithClonesTableOptions["pfconvParams"],
        additionalArgsForImportTsv
    )

	// Running SOI search for the data
	soiNodesResults := {}
	soiTreesResults := {}
	for soiDb in inputs.params.sequencesOfInterest {

		columnId := ""
		if soiDb.parameters.type == "nucleotide" {
			columnId = "n-seq-"
		} else if soiDb.parameters.type == "amino-acid" {
			columnId = "aa-seq-"
		} else {
			ll.panic("unknown alphabet: " + soiDb.parameters.type)
		}

		if soiDb.parameters.targetFeature == "CDR3" {
			columnId = columnId + "CDR3"
		} else if soiDb.parameters.targetFeature == "VDJRegion" {
			columnId = columnId + "VDJRegion"
		} else {
			ll.panic("unknown target feature: " + soiDb.parameters.targetFeature)
		}

		querySpec := treeNodes[columnId + ".spec"]
		queryData := treeNodes[columnId + ".data"]

		soiResult := render.create(soiTpl, {
			querySpec: querySpec,
			queryData: queryData,
			db: soiDb
		})

		soiNodesResults[soiDb.parameters.id] = soiResult.output("nodesResult")
		soiTreesResults[soiDb.parameters.id] = soiResult.output("treesResult")
	}

	tsvs := mixcrResults.output("tsvs")

    return {
		// combine columns into pFrame
        "trees": pframes.exportFrame(trees),
        // combine columns into pFrame
        "treeNodes": pframes.exportFrame(treeNodes),
        // combine columns into pFrame
        "treeNodesWithClones": pframes.exportFrame(treeNodesWithClones),

		"soiNodesResults": maps.mapValues(soiNodesResults, pframes.exportFrame),
		"soiTreesResults": maps.mapValues(soiTreesResults, pframes.exportFrame),

        "tsvs": tsvs,

		"allelesLogs": mixcrResults.output("allelesLog"),
        "treesLogs": mixcrResults.output("treesLog"),

		"allelesReports": mixcrResults.output("allelesReport"),
        "treesReports": mixcrResults.output("treesReport"),
		"allelesReportsJson": mixcrResults.output("allelesReportJson"),
        "treesReportsJson": mixcrResults.output("treesReportJson")
	}
})
