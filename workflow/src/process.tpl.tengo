self := import("@platforma-sdk/workflow-tengo:tpl")

llPFrames := import("@platforma-sdk/workflow-tengo:pframes.ll")
ll := import("@platforma-sdk/workflow-tengo:ll")
maps := import("@platforma-sdk/workflow-tengo:maps")
assets := import("@platforma-sdk/workflow-tengo:assets")
render := import("@platforma-sdk/workflow-tengo:render")
xsv := import("@platforma-sdk/workflow-tengo:pframes.xsv")
smart := import("@platforma-sdk/workflow-tengo:smart")
text := import("text")
json := import("json")
exportSettings := import(":export-settings")
prepareDonorColumn := import(":prepare-donor-column")
pframes := import("@platforma-sdk/workflow-tengo:pframes")

reconstructShmTreesTpl := assets.importTemplate(":reconstruct-shm-trees")

mixcrShmTreesTpl := assets.importTemplate(":mixcr-shm-trees")
mixcrExportTpl := assets.importTemplate(":mixcr-export")

self.awaitState("firstDatasetSpec", "ResourceReady")
self.awaitState("datasets", { wildcard: "*" }, "AllInputsSet")
// this templete should run only after resolving of all inputs
// we don't need to wait for file content, just refs
self.awaitState("datasets", { wildcard: "*" }, "data", "InputsLocked")
// but we need spec already
self.awaitState("datasets", { wildcard: "*" }, "spec", "ResourceReady")

// Using match instead of exact name to make fields effectively optional,
// in cases where built-in library is used, null resource is passed as library.
// Match don't throw error if no fields matched, opposite to exact name.
self.awaitState("library", { match: "^spec$" }, "ResourceReady")
self.awaitState("library", { match: "^data$" }, "AllInputsSet") // change to InputsLocked after fix
// self.awaitState({ match: "^library$" }, "BQueryResultMulti")

self.awaitState("donorColumn", "ResourceReady")
self.awaitState("params", "ResourceReady")

soiTpl := assets.importTemplate(":soi")

self.body(func(inputs) {
	// overall description of data that we have.
    dataDescription := {
		hasUmiTags: false,
		hasCellTags: false,
		// will be filled
		coveredFeatures: [],
		assemblingFeature: undefined,
		cellsAssembled: false
	}

	blockId := inputs.blockId

	library := inputs.library
	libraryFormat := library.spec.annotations["pl7.app/vdj/libraryFormat"]

	// clonotypingBlockId -> "bulk" | "sc"
	datasetTypes := {}

	assemblingFeature := ""
	for clonotypingBlockId, dataset in inputs.datasets {
		presetAnnotations := dataset.spec.annotations

		ll.assert(!is_undefined(presetAnnotations), "No annotations in dataset specs")

		datasetTypes[clonotypingBlockId] = "bulk"

		if presetAnnotations["mixcr.com/cellTags"] != "" {
			dataDescription.hasCellTags = true
		}
		if presetAnnotations["mixcr.com/umiTags"] != "" {
			dataDescription.hasUmiTags = true
		}
		if presetAnnotations["mixcr.com/cellsAssembled"] == "true" {
			dataDescription.cellsAssembled = true
			datasetTypes[clonotypingBlockId] = "sc"
		}
		dataDescription.coveredFeatures = text.re_split(',', presetAnnotations["mixcr.com/coveredFeaturesOnExport"])
		// check that assemblingFeature feature is the same. If so, coveredFeatures will be the same too
		if (assemblingFeature == "") {
			assemblingFeature = presetAnnotations["mixcr.com/assemblingFeature"]
		} else if (assemblingFeature != presetAnnotations["mixcr.com/assemblingFeature"]) {
			ll.panic("Assmble features should be the same to process tress. Got " + assemblingFeature + " and " + presetAnnotations["mixcr.com/assemblingFeature"])
		}
	}

	// adding assembling feature
	dataDescription.assemblingFeature = assemblingFeature

	// there should be call join on pfFrames, but it's not implements, so we will do it by hand
	dataGroupedByDonorId := prepareDonorColumn.groupDataByDonorId(inputs.donorColumn, inputs.datasets, inputs.firstDatasetSpec)

	shmtResults := pframes.processColumn(
		dataGroupedByDonorId,
		mixcrShmTreesTpl,
		[ {
			name: "alleles",
			type: "Resource",
			spec: {
				name: "mixcr.com/shmt/alleles",
				valueType: "FileMap",
			}
		}, {
			name: "downsampled",
			type: "Resource",
			spec: {
				name: "mixcr.com/shmt/downsampled",
				valueType: "FileMap",
			}
		}, {
			name: "shmTrees",
			type: "Resource",
			spec: {
				name: "mixcr.com/shmt",
				valueType: "File",
			}
		}, {
			name: "allelesLog",
			type: "Resource",
			spec: {
				name: "mixcr.com/shmt/allelesLog",
				valueType: "Log",
			}
		}, {
			name: "treesLog",
			type: "Resource",
			spec: {
				name: "mixcr.com/shmt/treesLog",
				valueType: "Log",
		}, {
			name: "allelesReport",
			type: "Resource",
			spec: {
				name: "mixcr.com/shmt/allelesReport",
				valueType: "File",
			}
		}, {
			name: "treesReport",
			type: "Resource",
			spec: {
				name: "mixcr.com/shmt/treesReport",
				valueType: "File",
			}
		}, {
			name: "allelesReportJson",
			type: "Resource",
			spec: {
				name: "mixcr.com/shmt/allelesReportJson",
				valueType: "File",
			}
		}, {
			name: "treesReportJson",
			type: "Resource",
			spec: {
				name: "mixcr.com/shmt/treesReportJson",
				valueType: "File",
			}
		} ],
		{
			aggregate: [1, 2],
			traceSteps: [{type: "milaboratories.mixcr-shm-trees", id: blockId, importance: 19, label: "SHM Trees"}],
			extra: {
				library: is_undefined(library) ? smart.createNullResource() : library.data,
				globalParams: maps.merge(inputs.params, {
					datasetTypes: datasetTypes,
					libraryFormat: libraryFormat
				})
			}
		}
	)

	// collect params for running export commands and to parse result tsv files into pColumns
	shmTreeTableOptions := exportSettings.shmTree(dataDescription)
	shmTreeNodesTableOptions := exportSettings.shmTreeNodes(dataDescription)
	shmTreeNodesWithClonesTableOptions := exportSettings.shmTreeNodesWithClones(dataDescription, inputs.donorColumn)
	shmTreeNodesUniqueIsotypeTableOptions := exportSettings.shmTreeNodesUniqueIsotype(dataDescription)

	shmtResults := pframes.processColumn(
		shmtResults.output("shmTrees"),
		mixcrExportTpl,
		[{
			type: "Xsv",
			xsvType: "tsv",
			settings: shmTreeTableOptions.pfconvParams,
			name: "trees"
		}, {
			type: "Xsv",
			xsvType: "tsv",
			settings: shmTreeNodesTableOptions.pfconvParams,
			name: "treeNodes"
		}, {
			type: "Xsv",
			xsvType: "tsv",
			settings: shmTreeNodesWithClonesTableOptions.pfconvParams,
			name: "treeNodesWithClones"
		}, {
			type: "Xsv",
			xsvType: "tsv",
			settings: shmTreeNodesUniqueIsotypeTableOptions.pfconvParams,
			name: "treeNodesUniqueIsotype"
		}],
		{
			extra: {
				library: is_undefined(library) ? smart.createNullResource() : library.data,
				params:{
					libraryFormat: libraryFormat,
					shmTreeArgs: shmTreeTableOptions.cmdArgs,
					shmTreeNodesArgs: shmTreeNodesTableOptions.cmdArgs,
					shmTreeNodesWithClonesArgs: shmTreeNodesWithClonesTableOptions.cmdArgs,
					shmTreeNodesUniqueIsotypeArgs: shmTreeNodesUniqueIsotypeTableOptions.cmdArgs
				}
			}
		}
	)
	// TODO that call is too low level. Should be replaced with something that works with pColumns, not data only
	mixcrResults := llPFrames.aggregate(
		// files to iterate through
		dataGroupedByDonorId.data,
		// columns not to combine - sampleId and mixcrBlockId
		[1, 2],
		reconstructShmTreesTpl,
		// all the outputs that should be gethered
		[
			{
				name: "trees",
				type: "Resource"
			}, {
				name: "treeNodes",
				type: "Resource"
			}, {
				name: "treeNodesWithClones",
				type: "Resource"
			}, {
				name: "treeNodesUniqueIsotype",
				type: "Resource"
			}, {
				name: "tsvs",
				type: "Resource"
			}, {
				name: "allelesLog",
				type: "Resource"
			}, {
				name: "treesLog",
				type: "Resource"
			}, {
				name: "allelesReport",
				type: "Resource"
			}, {
				name: "treesReport",
				type: "Resource"
			}, {
				name: "allelesReportJson",
				type: "Resource"
			}, {
				name: "treesReportJson",
				type: "Resource"
			}
		],
		false,
		// inputs
		{
			shmTreeTableOptions: shmTreeTableOptions,
			shmTreeTableArgs: shmTreeTableOptions.cmdArgs,
			shmTreeNodesTableOptions: shmTreeNodesTableOptions,
			shmTreeNodesWithClonesTableOptions: shmTreeNodesWithClonesTableOptions,
			shmTreeNodesWithClonesTableArgs: shmTreeNodesWithClonesTableOptions.cmdArgs,
			shmTreeNodesUniqueIsotypeTableOptions: shmTreeNodesUniqueIsotypeTableOptions,
			library: is_undefined(library) ? smart.createNullResource() : library.data,
			globalParams: maps.merge(
				inputs.params,
				{
					datasetTypes: datasetTypes,
					libraryFormat: libraryFormat
				}
			)
		}
	)

	// donorId axis is inherited from dataGroupedByDonorId and we should specify it explicitly (other axes will be supplied by pfconvParams)
	additionalArgsForImportTsv := {
		additionalAxesSpec: dataGroupedByDonorId.spec["axesSpec"][:1]
	}

	// ll.print("__THE_LOG__ " + string(json.encode(additionalArgsForImportTsv)))

	trees := xsv.importFileMap(
        mixcrResults.output("trees"),
        "tsv",
        shmTreeTableOptions.pfconvParams,
        additionalArgsForImportTsv
    )

	treeNodes := xsv.importFileMap(
        mixcrResults.output("treeNodes"),
        "tsv",
        shmTreeNodesTableOptions.pfconvParams,
        additionalArgsForImportTsv
    )

	treeNodesWithClones := xsv.importFileMap(
        mixcrResults.output("treeNodesWithClones"),
        "tsv",
        shmTreeNodesWithClonesTableOptions.pfconvParams,
        additionalArgsForImportTsv
    )

	treeNodesUniqueIsotype := xsv.importFileMap(
        mixcrResults.output("treeNodesUniqueIsotype"),
        "tsv",
        shmTreeNodesUniqueIsotypeTableOptions.pfconvParams,
        additionalArgsForImportTsv
	)

	// Running SOI search for the data
	soiNodesResults := {}
	soiTreesResults := {}
	for soiDb in inputs.params.sequencesOfInterest {

		if len(soiDb.sequences) == 0 {
			continue
		}

		columnId := ""
		if soiDb.parameters.type == "nucleotide" {
			columnId = "n-seq-"
		} else if soiDb.parameters.type == "amino-acid" {
			columnId = "aa-seq-"
		} else {
			ll.panic("unknown alphabet: " + soiDb.parameters.type)
		}

		if soiDb.parameters.targetFeature == "CDR3" {
			columnId = columnId + "CDR3"
		} else if soiDb.parameters.targetFeature == "VDJRegion" {
			columnId = columnId + "VDJRegion"
		} else {
			ll.panic("unknown target feature: " + soiDb.parameters.targetFeature)
		}

		querySpec := treeNodes[columnId + ".spec"]
		queryData := treeNodes[columnId + ".data"]

		soiResult := render.create(soiTpl, {
			querySpec: querySpec,
			queryData: queryData,
			db: soiDb
		})

		soiNodesResults[soiDb.parameters.id] = soiResult.output("nodesResult")
		soiTreesResults[soiDb.parameters.id] = soiResult.output("treesResult")
	}

	tsvs := mixcrResults.output("tsvs")

    return {
		// combine columns into pFrame
        trees: pframes.exportFrame(trees),
        // combine columns into pFrame
        treeNodes: pframes.exportFrame(treeNodes),
        // combine columns into pFrame
        treeNodesWithClones: pframes.exportFrame(treeNodesWithClones),
		// combine columns into pFrame
		treeNodesUniqueIsotype: pframes.exportFrame(treeNodesUniqueIsotype),

		soiNodesResults: maps.mapValues(soiNodesResults, pframes.exportFrame),
		soiTreesResults: maps.mapValues(soiTreesResults, pframes.exportFrame),

        tsvs: tsvs,

		allelesLogs: mixcrResults.output("allelesLog"),
        treesLogs: mixcrResults.output("treesLog"),

		allelesReports: mixcrResults.output("allelesReport"),
        treesReports: mixcrResults.output("treesReport"),
		allelesReportsJson: mixcrResults.output("allelesReportJson"),
        treesReportsJson: mixcrResults.output("treesReportJson")
	}
})
