self := import("@platforma-sdk/workflow-tengo:tpl")

llPFrames := import("@platforma-sdk/workflow-tengo:pframes.ll")
ll := import("@platforma-sdk/workflow-tengo:ll")
maps := import("@platforma-sdk/workflow-tengo:maps")
assets := import("@platforma-sdk/workflow-tengo:assets")
render := import("@platforma-sdk/workflow-tengo:render")
xsv := import("@platforma-sdk/workflow-tengo:pframes.xsv")
smart := import("@platforma-sdk/workflow-tengo:smart")
text := import("text")
json := import("json")
exportSettings := import(":export-settings")
prepareDonorColumn := import(":prepare-donor-column")
pframes := import("@platforma-sdk/workflow-tengo:pframes")
tablesAggregation := import(":tables-aggregation")

// reconstructShmTreesTpl := assets.importTemplate(":reconstruct-shm-trees")

mixcrShmTreesTpl := assets.importTemplate(":mixcr-shm-trees")
mixcrExportTpl := assets.importTemplate(":mixcr-export")

self.awaitState("datasets", { wildcard: "*" }, "AllInputsSet")
// this templete should run only after resolving of all inputs
// we don't need to wait for file content, just refs
self.awaitState("datasets", { wildcard: "*" }, "data", "InputsLocked")
// but we need spec already
self.awaitState("datasets", { wildcard: "*" }, "spec", "ResourceReady")

// Using match instead of exact name to make fields effectively optional,
// in cases where built-in library is used, null resource is passed as library.
// Match don't throw error if no fields matched, opposite to exact name.
self.awaitState("library", { match: "^spec$" }, "ResourceReady")
self.awaitState("library", { match: "^data$" }, "AllInputsSet") // change to InputsLocked after fix
// self.awaitState({ match: "^library$" }, "BQueryResultMulti")

self.awaitState("donorColumn", "ResourceReady")
self.awaitState("params", "ResourceReady")
self.awaitState("etc", "ResourceReady")

soiTpl := assets.importTemplate(":soi")

self.body(func(inputs) {
	// overall description of data that we have.
    dataDescription := {
		hasUmiTags: false,
		hasCellTags: false,
		// will be filled
		coveredFeatures: [],
		assemblingFeature: undefined,
		cellsAssembled: false
	}

	blockId := inputs.etc.blockId
	firstDatasetSpec := inputs.etc.firstDatasetSpec

	library := inputs.library
	libraryFormat := library.spec.annotations["pl7.app/vdj/libraryFormat"]

	// clonotypingBlockId -> "bulk" | "sc"
	datasetTypes := {}

	assemblingFeature := ""
	for clonotypingBlockId, dataset in inputs.datasets {
		presetAnnotations := dataset.spec.annotations

		ll.assert(!is_undefined(presetAnnotations), "No annotations in dataset specs")

		datasetTypes[clonotypingBlockId] = "bulk"

		if presetAnnotations["mixcr.com/cellTags"] != "" {
			dataDescription.hasCellTags = true
		}
		if presetAnnotations["mixcr.com/umiTags"] != "" {
			dataDescription.hasUmiTags = true
		}
		if presetAnnotations["mixcr.com/cellsAssembled"] == "true" {
			dataDescription.cellsAssembled = true
			datasetTypes[clonotypingBlockId] = "sc"
		}
		dataDescription.coveredFeatures = text.re_split(',', presetAnnotations["mixcr.com/coveredFeaturesOnExport"])
		// check that assemblingFeature feature is the same. If so, coveredFeatures will be the same too
		if (assemblingFeature == "") {
			assemblingFeature = presetAnnotations["mixcr.com/assemblingFeature"]
		} else if (assemblingFeature != presetAnnotations["mixcr.com/assemblingFeature"]) {
			ll.panic("Assmble features should be the same to process tress. Got " + assemblingFeature + " and " + presetAnnotations["mixcr.com/assemblingFeature"])
		}
	}

	// adding assembling feature
	dataDescription.assemblingFeature = assemblingFeature

	// there should be call join on pfFrames, but it's not implements, so we will do it by hand
	dataGroupedByDonorId := prepareDonorColumn.groupDataByDonorId(inputs.donorColumn, inputs.datasets, firstDatasetSpec)

	shmtResults := pframes.processColumn(
		dataGroupedByDonorId,
		mixcrShmTreesTpl,
		[ {
			name: "alleles",
			type: "Resource",
			spec: {
				kind: "PColumn",
				name: "mixcr.com/shmt/alleles",
				valueType: "FileMap"
			}
		}, {
			name: "downsampled",
			type: "Resource",
			spec: {
				kind: "PColumn",
				name: "mixcr.com/shmt/downsampled",
				valueType: "FileMap"
			}
		}, {
			name: "shmt",
			type: "Resource",
			spec: {
				kind: "PColumn",
				name: "mixcr.com/shmt",
				valueType: "File"
			}
		}, {
			name: "allelesLog",
			type: "Resource",
			spec: {
				kind: "PColumn",
				name: "mixcr.com/shmt/allelesLog",
				valueType: "Log"
			}
		}, {
			name: "treesLog",
			type: "Resource",
			spec: {
				kind: "PColumn",
				name: "mixcr.com/shmt/treesLog",
				valueType: "Log"
			}
		}, {
			name: "allelesReport",
			type: "Resource",
			spec: {
				kind: "PColumn",
				name: "mixcr.com/shmt/allelesReport",
				valueType: "File"
			}
		}, {
			name: "treesReport",
			type: "Resource",
			spec: {
				kind: "PColumn",
				name: "mixcr.com/shmt/treesReport",
				valueType: "File"
			}
		}, {
			name: "allelesReportJson",
			type: "Resource",
			spec: {
				kind: "PColumn",
				name: "mixcr.com/shmt/allelesReportJson",
				valueType: "File"
			}
		}, {
			name: "treesReportJson",
			type: "Resource",
			spec: {
				kind: "PColumn",
				name: "mixcr.com/shmt/treesReportJson",
				valueType: "File"
			}
		} ],
		{
			aggregate: [1, 2],
			traceSteps: [{type: "milaboratories.mixcr-shm-trees", id: blockId, importance: 19, label: "SHM Trees"}],
			extra: {
				library: is_undefined(library) ? smart.createNullResource() : library.data,
				globalParams: maps.merge(inputs.params, {
					datasetTypes: datasetTypes,
					libraryFormat: libraryFormat
				})
			}
		}
	)

	// collect params for running export commands and to parse result tsv files into pColumns
	shmTreeTableOptions := exportSettings.shmTree(dataDescription)
	shmTreeNodesTableOptions := exportSettings.shmTreeNodes(dataDescription)
	shmTreeNodesWithClonesTableOptions := exportSettings.shmTreeNodesWithClones(dataDescription, inputs.donorColumn)
	shmTreeNodesUniqueIsotypeTableOptions := exportSettings.shmTreeNodesUniqueIsotype(dataDescription)

	exportResults := pframes.processColumn(
		shmtResults.output("shmt"),
		mixcrExportTpl,
		[ {
			type: "Xsv",
			xsvType: "tsv",
			settings: shmTreeTableOptions.pfconvParams,
			name: "trees"
		}, {
			type: "Xsv",
			xsvType: "tsv",
			settings: shmTreeNodesTableOptions.pfconvParams,
			name: "treeNodes"
		}, {
			type: "Xsv",
			xsvType: "tsv",
			settings: shmTreeNodesWithClonesTableOptions.pfconvParams,
			name: "treeNodesWithClones"
		}, {
			type: "Xsv",
			xsvType: "tsv",
			settings: shmTreeNodesUniqueIsotypeTableOptions.pfconvParams,
			name: "treeNodesUniqueIsotype"
		} ],
		{
			extra: {
				library: is_undefined(library) ? smart.createNullResource() : library.data,
				params:{
					libraryFormat: libraryFormat,
					shmTreeArgs: shmTreeTableOptions.cmdArgs,
					shmTreeNodesArgs: shmTreeNodesTableOptions.cmdArgs,
					shmTreeNodesWithClonesArgs: shmTreeNodesWithClonesTableOptions.cmdArgs,
					shmTreeNodesUniqueIsotypeArgs: shmTreeNodesUniqueIsotypeTableOptions.cmdArgs,
					shmTreeEnsureUniquenessParams: tablesAggregation.ensureUniquenessParamsFromPconvParams(shmTreeTableOptions.pfconvParams),
					shmTreeNodesEnsureUniquenessParams: tablesAggregation.ensureUniquenessParamsFromPconvParams(shmTreeNodesTableOptions.pfconvParams),
					shmTreeNodesWithClonesEnsureUniquenessParams: tablesAggregation.ensureUniquenessParamsFromPconvParams(shmTreeNodesWithClonesTableOptions.pfconvParams),
					shmTreeNodesUniqueIsotypeEnsureUniquenessParams: tablesAggregation.ensureUniquenessParamsFromPconvParams(shmTreeNodesUniqueIsotypeTableOptions.pfconvParams)
				}
			}
		}
	)

	// donorId axis is inherited from dataGroupedByDonorId and we should specify it explicitly (other axes will be supplied by pfconvParams)
	additionalArgsForImportTsv := {
		additionalAxesSpec: dataGroupedByDonorId.spec["axesSpec"][:1]
	}

	// ll.print("__THE_LOG__ " + string(json.encode(additionalArgsForImportTsv)))

	// Running SOI search for the data
	soiNodesResults := {}
	soiTreesResults := {}
	for soiDb in inputs.params.sequencesOfInterest {

		if len(soiDb.sequences) == 0 {
			continue
		}

		columnId := ""
		if soiDb.parameters.type == "nucleotide" {
			columnId = "n-seq-"
		} else if soiDb.parameters.type == "amino-acid" {
			columnId = "aa-seq-"
		} else {
			ll.panic("unknown alphabet: " + soiDb.parameters.type)
		}

		if soiDb.parameters.targetFeature == "CDR3" {
			columnId = columnId + "CDR3"
		} else if soiDb.parameters.targetFeature == "VDJRegion" {
			columnId = columnId + "VDJRegion"
		} else {
			ll.panic("unknown target feature: " + soiDb.parameters.targetFeature)
		}

		querySpec := exportResults.outputSpec("treeNodes", columnId)
		queryData := exportResults.outputData("treeNodes", columnId)

		soiResult := render.create(soiTpl, {
			querySpec: querySpec,
			queryData: queryData,
			db: soiDb
		})

		soiNodesResults[soiDb.parameters.id] = soiResult.output("nodesResult")
		soiTreesResults[soiDb.parameters.id] = soiResult.output("treesResult")
	}


	trees := exportResults.xsvOutputFrame("trees")

	treeNodes := exportResults.xsvOutputFrame("treeNodes")

	treeNodesWithClones := exportResults.xsvOutputFrame("treeNodesWithClones")

	treeNodesUniqueIsotype := exportResults.xsvOutputFrame("treeNodesUniqueIsotype")

    return {
		alleles: shmtResults.output("alleles"),
		downsampled: shmtResults.output("downsampled"),
		shmt: shmtResults.output("shmt"),

        trees: trees,
        treeNodes: treeNodes,
        treeNodesWithClones: treeNodesWithClones,
		treeNodesUniqueIsotype: treeNodesUniqueIsotype,

		soiNodesResults: maps.mapValues(soiNodesResults, pframes.exportFrame),
		soiTreesResults: maps.mapValues(soiTreesResults, pframes.exportFrame),

		allelesLogs: shmtResults.outputData("allelesLog"),
        treesLogs: shmtResults.outputData("treesLog"),

		allelesReports: shmtResults.outputData("allelesReport"),
        treesReports: shmtResults.outputData("treesReport"),
		allelesReportsJson: shmtResults.outputData("allelesReportJson"),
        treesReportsJson: shmtResults.outputData("treesReportJson")
	}
})
