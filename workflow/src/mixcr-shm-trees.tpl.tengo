//tengo:hash_override 33125CD9-6F67-46B3-AA68-0FCD825B51BA

self := import("@platforma-sdk/workflow-tengo:tpl")
pConstants := import("@platforma-sdk/workflow-tengo:pframes.constants")
ll := import("@platforma-sdk/workflow-tengo:ll")
assets := import("@platforma-sdk/workflow-tengo:assets")
exec := import("@platforma-sdk/workflow-tengo:exec")
smart := import("@platforma-sdk/workflow-tengo:smart")
maps := import("@platforma-sdk/workflow-tengo:maps")
times := import("times")

json := import("json")

// for usage in aggregate function, we should specify all outputs that will be used
self.defineOutputs(
    "alleles", "downsampled", "shmt",
    "allelesLog", "treesLog",
    "allelesReport", "treesReport",
    "allelesReportJson", "treesReportJson"
)

// import MiXCR as a software to use
mixcrSw := assets.importSoftware("@platforma-open/milaboratories.software-mixcr:main")

// env for MiXCR to format progress messages
progressPrefix := "[==PROGRESS==]"

self.body(func(inputs) {
	inputData := inputs[pConstants.VALUE_FIELD_NAME]
    globalParams := inputs.globalParams
    datasetTypes := globalParams.datasetTypes
    library := inputs.library
    libraryFormat := globalParams.libraryFormat
    downsampling := globalParams.downsampling

    ll.assert(!is_undefined(datasetTypes), "datasetTypes undefined")

    addLibraryFile := func(cmdBuilder) {
        if !is_undefined(library) {
            if libraryFormat == "repseqio.json.gz" {
                cmdBuilder.addFile("library.json.gz", library)
            } else {
                cmdBuilder.addFile("library.json", library)
            }
        }
    }

    // seed := times.time_string(times.now())

    //
    // Alleles inference
    //

    allelesCmdBuilder := exec.builder().
        printErrStreamToStdout().
        secret("MI_LICENSE", "MI_LICENSE").
        env("MI_PROGRESS_PREFIX", progressPrefix).
        // env("SEED", seed).
        software(mixcrSw).
        arg("findAlleles").
        arg("--report").arg("report.txt").
        saveFile("report.txt").
        arg("--json-report").arg("report.json").
        saveFile("report.json").
        // template specifies where result files will be written
        arg("--output-template").arg("alleles/{file_name}.clns").
        env("CIDADHOC", "123")

    addLibraryFile(allelesCmdBuilder)

    if !is_undefined(globalParams.seed) {
        allelesCmdBuilder.env("SEED", globalParams.seed)
    }

    entries := []
    for sKey, inputFile in inputData.inputs() {
        key := json.decode(sKey)
        sampleId := key[0]
        clonotypingBlockId := key[1]
        // file name should encode axis values. It will be parsed by xsv.importFileMap afterwards to restore axis for clones data
        fileName := sampleId + "___" + clonotypingBlockId + ".clns"
        entries = append(entries, {
            clonotypingBlockId: clonotypingBlockId,
            sampleId: sampleId,
            fileName: fileName,
            input: inputFile
        })
    }

    for entry in entries {
        allelesCmdBuilder.addFile(entry.fileName, entry.input).
            arg(entry.fileName).
            saveFile("alleles/" + entry.fileName)
    }

    alleles := allelesCmdBuilder.run()

    for entry in entries {
        entry.afterAlleles = alleles.getFile("alleles/" + entry.fileName)
        entry.treesInput = entry.afterAlleles
    }

    //
    // Optional downsampling
    //

    if !is_undefined(downsampling) {
        downsamplingParam := ""
        if downsampling.type == "CountReadsFixed" {
            downsamplingParam = "count-reads-fixed-" + string(downsampling.number)
        } else if downsampling.type == "CountMoleculesFixed" {
            downsamplingParam = "count-molecule-fixed-" + string(downsampling.number)
        } else if downsampling.type == "TopClonotypesByReads" {
            downsamplingParam = "top-reads-" + string(downsampling.number)
        } else if downsampling.type == "TopClonotypesByMolecules" {
            downsamplingParam = "top-molecule-" + string(downsampling.number)
        } else if downsampling.type == "CumulativeTopClonotypesByReads" {
            downsamplingParam = "cumtop-reads-" + string(downsampling.percent)
        } else if downsampling.type == "CumulativeTopClonotypesByMolecules" {
            downsamplingParam = "cumtop-molecule-" + string(downsampling.percent)
        } else {
            ll.panic("Unknown downsampling type: " + downsampling.type)
        }

        for entry in entries {
            if datasetTypes[entry.clonotypingBlockId] == "bulk" {
                downsamplingCmdBuilder := exec.builder().
                    printErrStreamToStdout().
                    secret("MI_LICENSE", "MI_LICENSE").
                    env("MI_PROGRESS_PREFIX", progressPrefix).
                    software(mixcrSw).
                    arg("downsample").
                    arg("--downsampling").
                    arg(downsamplingParam).
                    arg("clones.clns").
                    addFile("clones.clns", entry.afterAlleles).
                    saveFile("clones.downsampled.clns").
                    env("CIDADHOC", "123")
                addLibraryFile(downsamplingCmdBuilder)
                downsamplingCmd := downsamplingCmdBuilder.run()

                // overriding trees input with downsampled file
                entry.treesInput = downsamplingCmd.getFile("clones.downsampled.clns")
            }
        }
    }

    //
    // SHM trees inference
    //

    shmTreesCmdBuilder := exec.builder().
        printErrStreamToStdout().
        secret("MI_LICENSE", "MI_LICENSE").
        env("MI_PROGRESS_PREFIX", progressPrefix).
        software(mixcrSw).
        arg("findShmTrees").
        arg("--report").arg("report.txt").
        saveFile("report.txt").
        arg("--json-report").arg("report.json").
        saveFile("report.json").
        env("CIDADHOC", "123")

    if !is_undefined(globalParams.seed) {
        shmTreesCmdBuilder.env("SEED", globalParams.seed)
    }

    addLibraryFile(shmTreesCmdBuilder)

    for entry in entries {
        shmTreesCmdBuilder.
            addFile(entry.fileName, entry.treesInput).
            arg(entry.fileName)
    }

    shmTreesCmdBuilder.arg("output.shmt").saveFile("output.shmt")

    shmTrees := shmTreesCmdBuilder.run()
    outputShmt := shmTrees.getFile("output.shmt")

    return {
        // returning to be cached
        alleles: smart.createMapResource(maps.mapValues(entries, func(entry) {
            return entry.afterAlleles
        })),

        // returning to be cached
        downsampled: smart.createMapResource(maps.mapValues(entries, func(entry) {
            return entry.treesInput
        })),

        // main output
        shmt: outputShmt,

        // logs
        allelesLog: alleles.getStdoutStream(),
        treesLog: shmTrees.getStdoutStream(),

        // reports
        allelesReport: alleles.getFile("report.txt"),
        treesReport: shmTrees.getFile("report.txt"),

        // json reports
        allelesReportJson: alleles.getFile("report.json"),
        treesReportJson: shmTrees.getFile("report.json")
    }
})
